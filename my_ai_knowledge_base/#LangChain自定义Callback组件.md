# #LangChainè‡ªå®šä¹‰Callbackç»„ä»¶   
ä¸‹é¢æˆ‘ç»™ä½ ä¸€ä»½ **LangChain è‡ªå®šä¹‰ Callback ç»„ä»¶é«˜é˜¶æŒ‡å—**ï¼Œç›´å‡»ä¼ä¸šçº§å¤§æ¨¡å‹åº”ç”¨å¼€å‘ç—›ç‚¹ï¼Œæ¶µç›–è®¾è®¡ç†å¿µã€å®ç°æ–¹å¼ã€æœ€ä½³å®è·µä»¥åŠå®æˆ˜æ¡ˆä¾‹ã€‚ä½ ä½œä¸ºç¨‹åºå‘˜ï¼Œå¯ä»¥ç›´æ¥ä¸Šæ‰‹å†™ä»£ç ã€‚  
  
## ğŸš€** ä¸€ã€Callback çš„æ ¸å¿ƒä½œç”¨**  
åœ¨ LangChain ä¸­ï¼ŒCallback = ****äº‹ä»¶ç›‘å¬å™¨ / é’©å­å‡½æ•°****ï¼Œç”¨äºç›‘æ§å’Œæ‰©å±• LLMã€Agentã€Retrieverã€Chain çš„è¡Œä¸ºã€‚  
ä½œç”¨ï¼š  
1. **è®­ç»ƒ/æ¨ç†ç›‘æ§**  
    * token ç”Ÿæˆã€log probabilitiesã€completion stats  
2. **æ—¥å¿—è®°å½•**  
    * å¯¹è¯·æ±‚/å“åº”åšç»Ÿä¸€ç›‘æ§  
3. **è‡ªå®šä¹‰è¡Œä¸º**  
    * åœ¨æ¯æ¬¡ LLM è°ƒç”¨ã€Retriever æ£€ç´¢ã€Agent æ‰§è¡Œå‰åæ’å…¥é€»è¾‘  
4. **æ€§èƒ½ä¼˜åŒ–**  
    * ç»Ÿè®¡ latencyã€token usage  
5. **è°ƒè¯•ä¸å¯è§†åŒ–**  
    * ä¸ Weights & Biasesã€TensorBoard é›†æˆ  
Callback æ˜¯ LangChain å¯æ‰©å±•èƒ½åŠ›çš„æ ¸å¿ƒï¼Œä¼ä¸šçº§åº”ç”¨å‡ ä¹å¿…ç”¨ã€‚  
  
## ğŸ§±** äºŒã€Callback åŸºæœ¬ç»“æ„**  
LangChain æä¾›äº† **BaseCallbackHandler** åŸºç±»ï¼š  
```
from langchain.callbacks.base import BaseCallbackHandler

class MyCallbackHandler(BaseCallbackHandler):
    def on_llm_start(self, serialized, prompts, **kwargs):
        print("LLM å¼€å§‹è°ƒç”¨:", prompts)

    def on_llm_new_token(self, token, **kwargs):
        print("ç”Ÿæˆ token:", token)

    def on_llm_end(self, response, **kwargs):
        print("LLM è°ƒç”¨ç»“æŸ:", response)

    def on_chain_start(self, serialized, inputs, **kwargs):
        print("Chain å¼€å§‹:", inputs)

    def on_chain_end(self, outputs, **kwargs):
        print("Chain ç»“æŸ:", outputs)

```
æ ¸å¿ƒæ–¹æ³•ï¼šon_llm_start, on_llm_new_token, on_llm_end, on_chain_start, on_chain_end ç­‰  
  
## ğŸ”§** ä¸‰ã€è‡ªå®šä¹‰ Callback åœºæ™¯ç¤ºä¾‹**  
## 1ï¸âƒ£** Token çº§å®æ—¶æ—¥å¿—**  
```
class TokenLoggerCallback(BaseCallbackHandler):
    def on_llm_new_token(self, token, **kwargs):
        print(token, end="", flush=True)

```
é€‚åˆï¼š  
* æµå¼ç”Ÿæˆå±•ç¤º  
* ChatGPT/DeepSeek å®æ—¶ token è¾“å‡º  
  
## 2ï¸âƒ£** LLM è°ƒç”¨è®¡æ•°ä¸æ€§èƒ½ç›‘æ§**  
```
import time

class PerfMonitorCallback(BaseCallbackHandler):
    def on_llm_start(self, serialized, prompts, **kwargs):
        self.start_time = time.time()

    def on_llm_end(self, response, **kwargs):
        duration = time.time() - self.start_time
        print(f"LLM è°ƒç”¨è€—æ—¶: {duration:.2f}s, tokenæ•°: {len(response['generation'][0]['text'])}")

```
ç”¨é€”ï¼š  
* æ€§èƒ½åˆ†æ  
* Token è®¡è´¹é¢„ä¼°  
* ç›‘æ§æ…¢è¯·æ±‚  
  
## 3ï¸âƒ£** ä¸ RAG æ£€ç´¢ç»“åˆ**  
```
class RetrieverLoggerCallback(BaseCallbackHandler):
    def on_retriever_start(self, serialized, query, **kwargs):
        print(f"æ£€ç´¢ query: {query}")

    def on_retriever_end(self, results, **kwargs):
        print(f"æ£€ç´¢åˆ°æ–‡æ¡£: {len(results)} æ¡")

```
åœ¨å¤§å‹ä¼ä¸šçŸ¥è¯†åº“ä¸­å¯ç”¨äºå®¡è®¡æ£€ç´¢æ•ˆæœã€‚  
  
## ğŸ› ** å››ã€å¦‚ä½•æ³¨å†Œ Callback**  
```
from langchain.llms import OpenAI
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate

llm = OpenAI(temperature=0)
prompt = PromptTemplate(input_variables=["text"], template="è¯·æ€»ç»“: {text}")
chain = LLMChain(llm=llm, prompt=prompt)

callback = TokenLoggerCallback()
chain.run("LangChain è‡ªå®šä¹‰ Callback ç¤ºä¾‹", callbacks=[callback])

```
æ³¨æ„ï¼šcallbacks æ”¯æŒåˆ—è¡¨ï¼Œå¯ä»¥åŒæ—¶æ³¨å†Œå¤šä¸ª Callback  
  
## ğŸ”¥** äº”ã€ç”Ÿäº§çº§é«˜çº§æŠ€å·§**  
1. **Callback é“¾å¼å¤„ç†**  
    * å¤šä¸ª Callback æŒ‰é¡ºåºæ‰§è¡Œ â†’ æ—¥å¿— + æ€§èƒ½ + ç›‘æ§åŒæ—¶å¤„ç†  
2. **å¼‚æ­¥ Callback**  
    * æ”¯æŒ async æ–¹æ³•ï¼Œé€‚åˆæµå¼ token / Agent æ‰§è¡Œ  
3. **äº‹ä»¶è¿‡æ»¤**  
    * åªç›‘å¬ LLM æˆ– Chain æˆ– Retrieverï¼Œå‡å°‘æ€§èƒ½å¼€é”€  
4. **é›†æˆç›‘æ§å¹³å°**  
    * Weights & Biasesã€Prometheusã€Grafana â†’ Callback è¾“å‡ºæ•°æ®ç›´æ¥ä¸ŠæŠ¥  
5. **å®‰å…¨å®¡è®¡**  
    * å¯¹æ•æ„Ÿæ–‡æ¡£æ£€ç´¢æˆ–ç”Ÿæˆè¿‡ç¨‹åšå®¡è®¡æ—¥å¿—  
6. **è‡ªå®šä¹‰æµæ§**  
    * Callback å¯ä»¥åœ¨ on_llm_new_token é‡ŒåŠ¨æ€æ‹¦æˆª/ä¿®æ”¹ token  
  
## ğŸ§©** å…­ã€å…¨åŠŸèƒ½ Callback ç¤ºä¾‹ï¼ˆç»¼åˆç¤ºèŒƒï¼‰**  
```
class FullFeatureCallback(BaseCallbackHandler):
    def __init__(self):
        self.start_time = None
        self.tokens = []

    def on_llm_start(self, serialized, prompts, **kwargs):
        self.start_time = time.time()
        print("LLM å¼€å§‹è°ƒç”¨")

    def on_llm_new_token(self, token, **kwargs):
        self.tokens.append(token)

    def on_llm_end(self, response, **kwargs):
        duration = time.time() - self.start_time
        print(f"LLM å®Œæˆ, æ€» tokenæ•°: {len(self.tokens)}, è€—æ—¶: {duration:.2f}s")
        print("ç”Ÿæˆå†…å®¹:", "".join(self.tokens))
        self.tokens = []

    def on_chain_start(self, serialized, inputs, **kwargs):
        print("Chain å¼€å§‹æ‰§è¡Œ:", inputs)

    def on_chain_end(self, outputs, **kwargs):
        print("Chain æ‰§è¡Œç»“æŸ:", outputs)

```
ä½¿ç”¨ï¼š  
```
callback = FullFeatureCallback()
chain.run("å†™ä¸€æ®µLangChain Callbackç¤ºä¾‹ä»£ç ", callbacks=[callback])

```
ä½ ä¼šå¾—åˆ° ****æµå¼ token è¾“å‡º + æ€» token ç»Ÿè®¡ + Chain è¾“å…¥è¾“å‡ºæ—¥å¿—****  
  
## ğŸ§ ** ä¸ƒã€æ€»ç»“å»ºè®®**  
* Callback = ****ä¼ä¸šçº§ç›‘æ§ + æ€§èƒ½åˆ†æ + æµå¼è¾“å‡º + å®‰å…¨å®¡è®¡****  
* ç”Ÿäº§ç³»ç»Ÿå»ºè®®ï¼š  
    1. **Token æµå¼æ—¥å¿—**  
    2. **æ€§èƒ½ç»Ÿè®¡**  
    3. **æ£€ç´¢æ—¥å¿—**  
    4. **å¤š Callback é“¾å¼ç»„åˆ**  
* é«˜é˜¶ç”¨æ³•ï¼š  
    * å¼‚æ­¥  
    * è‡ªå®šä¹‰æ‹¦æˆª token / query  
    * ä¸ŠæŠ¥ç›‘æ§å¹³å°  
  
å¦‚æœä½ æ„¿æ„ï¼Œæˆ‘å¯ä»¥å¸®ä½ ç”Ÿæˆï¼š  
1. **ä¸€ä¸ªå®Œæ•´ LangChain Callback æ¨¡å—æ¨¡æ¿**  
2. **é›†æˆ RAG + Retriever + Agent + Token æµå¼æ—¥å¿—**  
3. **ç”Ÿäº§çº§ç›‘æ§ç³»ç»Ÿï¼ˆPrometheus/W&Bï¼‰ä¸ Callback å¯¹æ¥ç¤ºä¾‹**  
ä½ å¸Œæœ›æˆ‘ç”Ÿæˆå“ªä¸€éƒ¨åˆ†ï¼Ÿ  
